{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPptsc6iJmHQZgQyYwe5Vhh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import webtext\n",
        "from nltk import FreqDist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnBYbB4yJDFG",
        "outputId": "9cb0ce4a-c8bf-4ac2-9871-4e532c33b797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4>\n",
        "Q1. Find stem and lemma words for the given words?\n",
        "\"cats\"\n",
        "\"trouble\"\n",
        "\"troubling\"\n",
        "\"troubled\"\n",
        "“having”\n",
        "“Corriendo”\n",
        "“at”\n",
        "“was”\n",
        "<b><h4>"
      ],
      "metadata": {
        "id": "_dJNL2z6FeDz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0nnZ5Ldy6HU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a073cf7d-4029-41ad-bae0-216842a8da3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word        Stem Word   Lemma Word  \n",
            "cats        cat         cat         \n",
            "trouble     troubl      trouble     \n",
            "troubling   troubl      troubling   \n",
            "troubled    troubl      troubled    \n",
            "having      have        having      \n",
            "Corriendo   corriendo   Corriendo   \n",
            "at          at          at          \n",
            "was         wa          wa          \n"
          ]
        }
      ],
      "source": [
        "st = PorterStemmer()\n",
        "lemma = WordNetLemmatizer()\n",
        "words = [\"cats\", \"trouble\", \"troubling\", \"troubled\", \"having\", \"Corriendo\", \"at\", \"was\"]\n",
        "print(\"{:<12}{:<12}{:<12}\".format(\"Word\",\"Stem Word\", \"Lemma Word\"))\n",
        "for word in words:\n",
        "    print(\"{:<12}{:<12}{:<12}\".format(word,st.stem(word),lemma.lemmatize(word)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4>\n",
        "Q2. Find stop words and BOW from the given paragraph.\n",
        "“The NLTK library is one of the oldest and most commonly used Python libraries for Natural Language Processing. NLTK supports stop word removal, and you can find the list of stop words in the corpus module. To remove stop words from a sentence, you can divide your text into words and then remove the word if it exits in the list of stop words provided by NLTK.”\n",
        "<b><h4>"
      ],
      "metadata": {
        "id": "aXF2BnTbF_ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The NLTK library is one of the oldest and most commonly used Python libraries for Natural Language Processing. NLTK supports stop word removal, and you can find the list of stop words in the corpus module. To remove stop words from a sentence, you can divide your text into words and then remove the word if it exits in the list of stop words provided by NLTK.\"\n",
        "word_tokens = np.unique(word_tokenize(text))\n",
        "stop_words = [word for word in word_tokens if word in stopwords.words('english')]\n",
        "bag_words = [word for word in word_tokens if not word.lower() in stopwords.words('english')]\n",
        "print(\"Stop Words : \" , stop_words)\n",
        "print(\"Bag of Words : \" , bag_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjmC6hlvKl4t",
        "outputId": "b8132471-ab2b-487b-de60-6ee76f9f3352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop Words :  ['a', 'and', 'by', 'can', 'for', 'from', 'if', 'in', 'into', 'is', 'it', 'most', 'of', 'the', 'then', 'you', 'your']\n",
            "Bag of Words :  [',', '.', 'Language', 'NLTK', 'Natural', 'Processing', 'Python', 'commonly', 'corpus', 'divide', 'exits', 'find', 'libraries', 'library', 'list', 'module', 'oldest', 'one', 'provided', 'removal', 'remove', 'sentence', 'stop', 'supports', 'text', 'used', 'word', 'words']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4>\n",
        "Q3. From the above paragraph print frequency of each word using NLTK."
      ],
      "metadata": {
        "id": "etDIqulFGetV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq = nltk.FreqDist(word_tokens)\n",
        "for key,value in freq.items():\n",
        "    print(\"{}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zTvT49E3co1",
        "outputId": "ba3d9d83-e984-4af1-d337-faeab77977b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The: 1\n",
            "NLTK: 3\n",
            "library: 1\n",
            "is: 1\n",
            "one: 1\n",
            "of: 3\n",
            "the: 5\n",
            "oldest: 1\n",
            "and: 3\n",
            "most: 1\n",
            "commonly: 1\n",
            "used: 1\n",
            "Python: 1\n",
            "libraries: 1\n",
            "for: 1\n",
            "Natural: 1\n",
            "Language: 1\n",
            "Processing: 1\n",
            ".: 3\n",
            "supports: 1\n",
            "stop: 4\n",
            "word: 2\n",
            "removal: 1\n",
            ",: 2\n",
            "you: 2\n",
            "can: 2\n",
            "find: 1\n",
            "list: 2\n",
            "words: 4\n",
            "in: 2\n",
            "corpus: 1\n",
            "module: 1\n",
            "To: 1\n",
            "remove: 2\n",
            "from: 1\n",
            "a: 1\n",
            "sentence: 1\n",
            "divide: 1\n",
            "your: 1\n",
            "text: 1\n",
            "into: 1\n",
            "then: 1\n",
            "if: 1\n",
            "it: 1\n",
            "exits: 1\n",
            "provided: 1\n",
            "by: 1\n"
          ]
        }
      ]
    }
  ]
}